{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tweepy\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "sys.path.append('../../')\n",
    "import config\n",
    "\n",
    "load_dotenv(os.path.join(config.PROJ_PATH, '.env')) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set twitter access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_twitter_access():\n",
    "  consumer_key = os.environ[\"API_KEY\"]\n",
    "  consumer_secret = os.environ[\"API_KEY_SECRET\"]\n",
    "  access_token = os.environ[\"ACCESS_TOKEN\"]\n",
    "  access_token_secret = os.environ[\"ACCESS_TOKEN_SECRET\"]\n",
    "\n",
    "  auth = tweepy.OAuth1UserHandler(\n",
    "    consumer_key, \n",
    "    consumer_secret, \n",
    "    access_token, \n",
    "    access_token_secret\n",
    "  )\n",
    "\n",
    "  api = tweepy.API(auth)\n",
    "\n",
    "  return api\n",
    "\n",
    "api = set_twitter_access()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create functions to read and save texts and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tweet_text(tweet:object, text_type='') -> None:\n",
    "    tweet_timestamp = str(tweet.created_at.strftime(\"%Y-%m-%d %H-%M-%S\"))\n",
    "    tweet_id = str(tweet.id)\n",
    "    txt_file_name = os.path.join(config.DATA_PATH_RAW_TEXTS, '{}_{}.txt'.format(tweet_timestamp, tweet_id))\n",
    "    \n",
    "    with open(txt_file_name, 'w', encoding=\"utf-8\") as txt_file:\n",
    "        try:\n",
    "            if text_type == 'retweet':\n",
    "                txt_file.write(tweet.retweeted_status.full_text)\n",
    "            else:\n",
    "                txt_file.write(tweet.full_text)\n",
    "            # txt_file.write(tweet.retweeted_status.full_text)\n",
    "        except AttributeError:\n",
    "            print('Unable to read text from tweet {}'.format(tweet.id))\n",
    "            print(\"=====\")\n",
    "\n",
    "    return None\n",
    "\n",
    "def DownloadFile(url:str, path_to_save:str) -> None:\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(path_to_save, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_tweet_image(tweet:object) -> None:\n",
    "    tweet_timestamp = str(tweet.created_at.strftime(\"%Y-%m-%d %H-%M-%S\"))\n",
    "    tweet_id = str(tweet.id)\n",
    "\n",
    "    try:\n",
    "        for media in tweet.entities.get(\"media\",[{}]):\n",
    "            #checks if there is any media-entity\n",
    "            if media.get(\"type\",None) == \"photo\":\n",
    "                tweet_media_id = str(media['id'])\n",
    "                filename = os.path.join(config.DATA_PATH_RAW_IMAGES, '{}_{}_{}.png'.format(tweet_timestamp, tweet_id, tweet_media_id))\n",
    "                DownloadFile(media[\"media_url\"], filename)\n",
    "    except AttributeError:\n",
    "        print('Unable to read medias from tweet {}'.format(tweet_id))\n",
    "        print(\"=====\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_related_to_vaw = ['que ficar em casa', 'mulher obediente', '√© divorciada', 'Ningu√©m vai acreditar em voc√™', \n",
    "    'N√£o presta nem pra cozinha', 'Mal sabe lavar uma roupa direito', 'burra', 'interesseira']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Interesseira OR vaca)\n",
      "@acervoglobo Sabe que que √© engra√ßado? √â que a Nicole bahls colocou o nome da vaca dela de Camila Queiroz, pq ela gosta muito da Camila\n",
      "RT @luscas: passando mal com os atores da globo recriando o meme da nicole bahls batizando a vaca de camila queiroz \n",
      "\n",
      "https://t.co/ktP4ZFMH‚Ä¶\n",
      "@celiamatta T√° cert√≠ssima!\n",
      "Eu acho que tem que doar ao m√°ximo... \n",
      "Mas vc t√° com cara que vai mandar merreca pra ele. M√£o de vaca!\n",
      "@bsjeweIed @ferrwzz @kurozakiiiii apertei sem querer vaca\n",
      "@TheAndyMelo nhaaa, se mudar de ideia apare√ßa \n",
      "tamo com saudade, vaca\n",
      "n√£o vou dar amei na sua foto mais n√£o sua puta intergal√°tica mini pizza interesseira cachorra puta cachorra\n",
      "@SamuelDias762 tu para, so pega sanguessuga interesseira kkkkkkkkkk\n",
      "Cansada de quem acha que td mundo tem que comer que nem uma vaca, caso contr√°rio t√° passando fome\n",
      "ah vai toma no cu vai sua vagabunda vadia fdp desgra√ßada ot√°ria sem amor invejosa puta vaca fudida rid√≠cula sua opini√£o n√£o me importa n√£o\n"
     ]
    }
   ],
   "source": [
    "def extract_tweets(to_extract, place:str=''):\n",
    "    query = \"\"\n",
    "    if place:\n",
    "        query += f'place:{place} AND '\n",
    "\n",
    "    if type(to_extract) is list:\n",
    "        keywords_query = ' OR '.join(to_extract)\n",
    "        query += f'({keywords_query})'\n",
    "    else:\n",
    "        query += to_extract\n",
    "    \n",
    "    print(query)\n",
    "    tweets_pages = []\n",
    "    for status in tweepy.Cursor(api.search_tweets,\n",
    "                                query, \n",
    "                                tweet_mode='extended', \n",
    "                                lang='pt', \n",
    "                                count=3).pages(3):\n",
    "        tweets_pages.append(status)\n",
    "\n",
    "    # Read tweets\n",
    "    for page in tweets_pages:\n",
    "        for tweet in page:\n",
    "            save_tweet_text(tweet)\n",
    "            print(tweet.full_text)\n",
    "\n",
    "            save_tweet_image(tweet)\n",
    "\n",
    "            if tweet.coordinates is not None:\n",
    "                print(tweet.coordinates)\n",
    "                print(tweet.geo)\n",
    "                print(tweet.contributors)\n",
    "                break\n",
    "\n",
    "extract_tweets(['Interesseira', 'vaca'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@59Corvette1 @MakeTexasBlue22 Trump kid did some collaboration w Russian spy to get dirt on Clinton‚Ä¶\n",
      "@MagNorris @Duderichy Watch the bear you might change your mind üòÇ\n",
      "Stacking clips all weekend ‚ú®üõπüíÉüèª https://t.co/52IgUjOLkc\n",
      "Pine Creek locked in a tight one with Ranch at the break. https://t.co/wgTr0fdvzU\n",
      "The most painful thing that ever happened to me was watching Lost for the 5th time, but the first time as an adult, and realizing it‚Äôs not nearly as good as I thought it was. I‚Äôll be in my room\n",
      "@its_m_reilly I wasn‚Äôt sure if it was Murphy or you. I hope that he‚Äôs much better!!\n",
      "Summer Boulder https://t.co/yNH0GV0rzk\n"
     ]
    }
   ],
   "source": [
    "tweets_pages = []\n",
    "for status in tweepy.Cursor(api.search_tweets,\n",
    "                            'place:\"new york city\" OR place:seattle OR place:fd70c22040963ac7', \n",
    "                            tweet_mode='extended',\n",
    "                            count=3).pages(3):\n",
    "    tweets_pages.append(status)\n",
    "\n",
    "for page in tweets_pages:\n",
    "    for tweet in page:\n",
    "\n",
    "        print(tweet.full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['_api', '_json', 'created_at', 'id', 'id_str', 'full_text', 'truncated', 'display_text_range', 'entities', 'extended_entities', 'metadata', 'source', 'source_url', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'author', 'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'lang'])\n",
      "dict_keys(['_api', '_json', 'id', 'id_str', 'name', 'screen_name', 'location', 'description', 'url', 'entities', 'protected', 'followers_count', 'friends_count', 'listed_count', 'created_at', 'favourites_count', 'utc_offset', 'time_zone', 'geo_enabled', 'verified', 'statuses_count', 'lang', 'contributors_enabled', 'is_translator', 'is_translation_enabled', 'profile_background_color', 'profile_background_image_url', 'profile_background_image_url_https', 'profile_background_tile', 'profile_image_url', 'profile_image_url_https', 'profile_banner_url', 'profile_link_color', 'profile_sidebar_border_color', 'profile_sidebar_fill_color', 'profile_text_color', 'profile_use_background_image', 'has_extended_profile', 'default_profile', 'default_profile_image', 'following', 'follow_request_sent', 'notifications', 'translator_type', 'withheld_in_countries'])\n",
      "dict_keys(['_api', 'id', 'url', 'place_type', 'name', 'full_name', 'country_code', 'country', 'contained_within', 'bounding_box', 'attributes'])\n"
     ]
    }
   ],
   "source": [
    "# Usefull tweet attributes [author(id, name, screen_name, location), user(id, name, screen_name, location), \n",
    "#                           geo, place, coordinates]\n",
    "print(vars(tweet).keys())\n",
    "print(vars(tweet.user).keys())\n",
    "print(vars(tweet.place).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1672707501186510848\n",
      "Summer Boulder https://t.co/yNH0GV0rzk\n",
      "2023-06-24 20:45:20+00:00\n",
      "326843207\n",
      "Yuta Notsu\n",
      "astronomy_stars\n",
      "http://pbs.twimg.com/profile_images/2240297038/274766_100003558210016_784855573_n_normal.jpg\n",
      "2011-06-30 15:44:26+00:00\n",
      "fd70c22040963ac7\n",
      "city\n",
      "Boulder\n",
      "United States\n",
      "US\n",
      "[[[-105.3017759, 39.953552], [-105.183597, 39.953552], [-105.183597, 40.094411], [-105.3017759, 40.094411]]]\n"
     ]
    }
   ],
   "source": [
    "print(tweet.id) # Id dado tweet (string)\n",
    "print(tweet.full_text) # Texto (string)\n",
    "['Interesseira', 'vaca'] # Palavras chaves para extra√ß√£o (list)\n",
    "print(tweet.created_at) # Data do tweet (timestamp)\n",
    "print(tweet.user.id_str) # Id do usu√°rio (string)\n",
    "print(tweet.user.name) # Nome completo (string)\n",
    "print(tweet.user.screen_name) # Screen_name\n",
    "print(tweet.user.profile_image_url) # Profile_image_url\n",
    "print(tweet.user.created_at)# Created_at (timestamp)\n",
    "print(tweet.place.id) # Id da localiza√ß√£o (string)\n",
    "print(tweet.place.place_type) # Tipo do lugar (string)\n",
    "print(tweet.place.name) # Nome (string)\n",
    "print(tweet.place.country) # Pa√≠s (string)\n",
    "print(tweet.place.country_code) # C√≥digo do pa√≠s (string)\n",
    "print(tweet.place.bounding_box.coordinates) # Coordenadas (list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object successfully saved to \"C:\\Users\\DCandelero\\Documents\\MBA - USP(Data Analytics)\\MBA_TCC\\data\\raw\\tweets\\1672728421217058816.pkl\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>keywords_extraction</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_profile_image_url</th>\n",
       "      <th>user_created_at</th>\n",
       "      <th>place_id</th>\n",
       "      <th>place_type</th>\n",
       "      <th>place_name</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1672728421217058816</td>\n",
       "      <td>RT @jjwanstar: Foi essa vagabunda aqui que com...</td>\n",
       "      <td>pt</td>\n",
       "      <td>b'[\"Vagabunda\"]'</td>\n",
       "      <td>2023-06-24 22:08:28+00:00</td>\n",
       "      <td>1246271282141896704</td>\n",
       "      <td>lu‚Å∑ üíú Take Two üé∂ Haegeum ü•¢D-DAY üíô</td>\n",
       "      <td>lu_winterflower</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1670982460...</td>\n",
       "      <td>2020-04-04 03:00:51+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1672728421217058816  RT @jjwanstar: Foi essa vagabunda aqui que com...   \n",
       "\n",
       "  lang keywords_extraction                created_at              user_id  \\\n",
       "0   pt    b'[\"Vagabunda\"]' 2023-06-24 22:08:28+00:00  1246271282141896704   \n",
       "\n",
       "                           user_name user_screen_name  \\\n",
       "0  lu‚Å∑ üíú Take Two üé∂ Haegeum ü•¢D-DAY üíô  lu_winterflower   \n",
       "\n",
       "                              user_profile_image_url  \\\n",
       "0  http://pbs.twimg.com/profile_images/1670982460...   \n",
       "\n",
       "            user_created_at place_id place_type place_name country  \\\n",
       "0 2020-04-04 03:00:51+00:00     None       None       None    None   \n",
       "\n",
       "  country_code coordinates  \n",
       "0         None        None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_scrap import extract_tweets\n",
    "\n",
    "keywords_to_extract = ['Vagabunda']\n",
    "extract_tweets(keywords_to_extract)\n",
    "\n",
    "extracted_tweets_path = os.path.join(config.DATA_PATH_WRANGLE_TWEETS, 'extracted_tweets.parquet')\n",
    "pd.read_parquet(extracted_tweets_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a07a04c00cde03960d99138a45053afb647678d3162cbd0e11bf4f9d35eb679"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
